# Pre-Boot Configuration of NCN Images

**NOTE:** Some of the documentation linked from this page mentions use of the Boot Orchestration Service (BOS). The use of BOS
is only relevant for booting compute nodes and can be ignored when working with NCN images.

This document describes the configuration of a Kubernetes NCN image. The same steps are relevant for modifying a Ceph NCN image.

1. (`ncn-mw#`) Locate the NCN image to be modified.

    This example assumes that the administrator wants to modify the Kubernetes image that is currently in use by NCNs. However, the steps are the same for any NCN SquashFS image.

    ```bash
    ARTIFACT_VERSION=<artifact-version>

    cray artifacts get ncn-images "k8s/${ARTIFACT_VERSION}/filesystem.squashfs" "./${ARTIFACT_VERSION}-filesystem.squashfs"

    cray artifacts get ncn-images "k8s/${ARTIFACT_VERSION}/kernel" "./${ARTIFACT_VERSION}-kernel"

    cray artifacts get ncn-images "k8s/${ARTIFACT_VERSION}/initrd" "./${ARTIFACT_VERSION}-initrd"

    export IMS_ROOTFS_FILENAME="${ARTIFACT_VERSION}-filesystem.squashfs"

    export IMS_KERNEL_FILENAME="${ARTIFACT_VERSION}-kernel"

    export IMS_INITRD_FILENAME="${ARTIFACT_VERSION}-initrd"
    ```

1. [Import External Image to IMS](../image_management/Import_External_Image_to_IMS.md).

    This document will instruct the administrator to set several environment variables, including the three set in
    the previous step.

1. [Create and Populate a VCS Configuration Repository](Create_and_Populate_a_VCS_Configuration_Repository.md).

   **NOTE:** If the image modification is a kernel-level change, then a new `initrd` may be created by invoking
   the following script: `/srv/cray/scripts/common/create-ims-initrd.sh`. This script is embedded in the
   NCN SquashFS. After the script completes, a new `initrd` will be available at `/boot/initrd`. CFS will
   automatically make this `initrd` available at the end of the CFS session.

   **WARNING:** If the above script is not run, then **DO NOT** download the `initrd` or `kernel` after the
   CFS session completes (see below). CFS will collect `/boot/initrd` and `/boot/vmlinuz` from the modified
   SquashFS. If the `create-ims-initrd.sh` script is not run, then these artifacts will be incorrect and
   will not be able to boot an NCN.

   If not modifying anything at the kernel-level, then there is no need to create a new `initrd`. In
   that case, use the existing `initrd`.

   **NOTE:** If desired, the default SSH *host* keys can be removed with a CFS Ansible task:

   ```yaml
   - name: Remove SSH host keys
     shell: rm -f /etc/ssh/*key*
     warn: false
   ```

   New host keys will be generated by `sshd` when the NCN boots for the first time.

1. [Create a CFS Configuration](Create_a_CFS_Configuration.md).

   **NOTE:** If the platform certificate is needed for the purpose of accessing Zypper repos,
   then the `csm.ncn.ca_cert` role can be added to a playbook within the `csm-config-management` repo.

   ```yaml
    # Install the platform certificate
    - role: csm.ncn.ca_cert
   ```

   The first layer in the CFS session should be similar to this, where `<example-playbook.yml>` is the playbook
   that includes the `csm.ncn.ca_cert` role.

   ```json
   "layers": [
   {
     "name": "csm-config",
     "cloneUrl": "https://api-gw-service-nmn.local/vcs/cray/csm-config-management.git",
     "playbook": "<example-playbook.yml>",
     "commit": "<git commit id>"
   },
   ```

   **NOTE:** There are three existing playbooks available for NCNs:

   - `ansible/ncn-worker_nodes.yml`
   - `ansible/ncn-storage_nodes.yml`
   - `ansible/ncn-master_nodes.yml`

1. [Create an Image Customization CFS Session](Create_an_Image_Customization_CFS_Session.md).

1. (`ncn-mw#`) Download the resultant NCN artifacts.

    **NOTE:** `${IMS_RESULTANT_IMAGE_ID}` is the `result_id` returned in the output of the last command
    in the previous step:

    ```bash
    cray cfs sessions describe example --format json | jq .status.artifacts
    ```

    **REMINDER:** If `create-ims-initrd.sh` was not run in the CFS session, then do *not* download the `initrd` and `kernel`. In that case,
    only download the SquashFS file.

    ```bash
    cray artifacts get boot-images "${IMS_RESULTANT_IMAGE_ID}/rootfs" "kubernetes-${ARTIFACT_VERSION}-1.squashfs"

    cray artifacts get boot-images "${IMS_RESULTANT_IMAGE_ID}/initrd" "initrd.img-${ARTIFACT_VERSION}-1.xz"

    cray artifacts get boot-images "${IMS_RESULTANT_IMAGE_ID}/kernel" "5.3.18-150300.59.43-default-${ARTIFACT_VERSION}-1.kernel"
    ```

1. (`ncn-mw#`) Upload NCN boot artifacts into S3.

    The `docs-csm` RPM must be installed on the NCN where this step is performed. See
    [Check for latest documentation](../../update_product_stream#check-for-latest-documentation).

    **NOTE:** If `create-ims-initrd.sh` was not run in the CFS session, then use the same `initrd` and `kernel` that were retrieved in the first step.

    ```bash
    /usr/share/doc/csm/scripts/ceph-upload-file-public-read.py --bucket-name ncn-images --key-name "k8s/${ARTIFACT_VERSION}-1/filesystem.squashfs" \
        --file-name "kubernetes-${ARTIFACT_VERSION}-1.squashfs"

    /usr/share/doc/csm/scripts/ceph-upload-file-public-read.py --bucket-name ncn-images --key-name "k8s/${ARTIFACT_VERSION}-1/initrd" \
        --file-name "initrd.img-${ARTIFACT_VERSION}-1.xz"

    /usr/share/doc/csm/scripts/ceph-upload-file-public-read.py --bucket-name ncn-images --key-name "k8s/${ARTIFACT_VERSION}-1/kernel" \
        --file-name "${ARTIFACT_VERSION}-1.kernel"
    ```

1. (`ncn-mw#`) Update NCN boot parameters.

    1. Get the existing `metal.server` setting for the component name (xname) of the node of interest:

        ```bash
        XNAME=<node-xname>
        METAL_SERVER=$(cray bss bootparameters list --hosts "${XNAME}" --format json | jq '.[] |."params"' \
            | awk -F 'metal.server=' '{print $2}' \
            | awk -F ' ' '{print $1}')
        echo "${METAL_SERVER}"
        ```

    1. Update the kernel, `initrd`, and metal server to point to the new artifacts.

        ```bash
        S3_ARTIFACT_PATH="ncn-images/k8s/${ARTIFACT_VERSION}-1"
        NEW_METAL_SERVER="http://rgw-vip.nmn/$S3_ARTIFACT_PATH"

        PARAMS=$(cray bss bootparameters list --hosts "${XNAME}" --format json | jq '.[] |."params"' | \
            sed "/metal.server/ s|${METAL_SERVER}|${NEW_METAL_SERVER}|" | \
            sed "s/metal.no-wipe=1/metal.no-wipe=0/" | \
            tr -d \")
        echo "${PARAMS}"
        ```

        In the output of the final echo command, verify that the value of `${NEW_METAL_SERVER}` was set correctly.

    1. Update BSS with the new boot parameters.

        ```bash
        cray bss bootparameters update --hosts "${XNAME}" \
            --kernel "s3://${S3_ARTIFACT_PATH}/kernel" \
            --initrd "s3://${S3_ARTIFACT_PATH}/initrd" \
            --params "${PARAMS}"
        ```

1. (`ncn-mw#`) Prepare for reboot.

   On the nodes being rebooted, run the following command to disable the boot loader and prepare the node to accept a new SquashFS.

   ```bash
   rm -rvf /metal/recovery/*
   ```

1. [Reboot the NCN](../node_management/Reboot_NCNs.md).

   **NOTE:** The linked procedure indicates that `metal.no-wipe` should be set to `1`. However, that is not true in this case, which
   is why it was explicitly set to `0` in an earlier step.
