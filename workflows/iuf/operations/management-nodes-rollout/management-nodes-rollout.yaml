#
# MIT License
#
# (C) Copyright 2022-2023 Hewlett Packard Enterprise Development LP
#
# Permission is hereby granted, free of charge, to any person obtaining a
# copy of this software and associated documentation files (the "Software"),
# to deal in the Software without restriction, including without limitation
# the rights to use, copy, modify, merge, publish, distribute, sublicense,
# and/or sell copies of the Software, and to permit persons to whom the
# Software is furnished to do so, subject to the following conditions:
#
# The above copyright notice and this permission notice shall be included
# in all copies or substantial portions of the Software.
#
# THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
# IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
# FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL
# THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR
# OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE,
# ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR
# OTHER DEALINGS IN THE SOFTWARE.
#
apiVersion: argoproj.io/v1alpha1
kind: WorkflowTemplate
metadata:
  name: management-nodes-rollout
spec:
  tolerations:
    - key: "node-role.kubernetes.io/master"
      operator: "Exists"
      effect: "NoSchedule"
  nodeSelector:
    kubernetes.io/hostname: ncn-m001
  entrypoint: main
  templates:
    - name: main
      parallelism: 1
      failFast: true
      metrics:
        prometheus:
        - name: operation_counter
          help: "Count of step execution by result status"
          labels:
            - key: "opname"
              value: "management-nodes-rollout"
            - key: stage
              value: "management-nodes-rollout"
            - key: type
              value: "global"
            - key: pname
              value: "global"
            - key: pversion
              value: "global"
            - key: status
              value: "{{status}}"
          counter:
            value: "1"
      inputs:
        parameters:
          - name: auth_token
          - name: global_params
      dag:
        tasks:
          - name: start-operation
            templateRef:
              name: workflow-template-record-time-template
              template: record-time-template
          - name: INFO-to-read
            dependencies:
              - start-operation
            templateRef:
              name: ssh-template
              template: shell-script
            arguments:
              parameters:
                - name: dryRun
                  value: "{{$.DryRun}}"
                - name: scriptContent
                  value: |
                    echo "NOTICE  this stage will not rollout storage nodes or ncn-m001. This will have to be done manually if rolling-out these nodes is desired."
                    echo "NOTICE  this stage will rollout workers and master nodes according to --limit-management-rollout and the node label iuf-prevent-rollout=true."
                    echo "NOTICE  check the argo pod logs from each step in the workflow to see what the step is doing."
          - name: verify-images-and-configuration
            dependencies:
              - INFO-to-read
            templateRef:
              name: ssh-template
              template: shell-script
            arguments:
              parameters:
                - name: dryRun
                  value: "{{$.DryRun}}"
                - name: scriptContent
                  value: |
                    rebuild_workers=false
                    rebuild_masters=false
                    limit_management_nodes=$(echo '{{inputs.parameters.global_params}}' | jq -r '.input_params.limit_management_nodes[]')
                    if [[ -n $(echo $limit_management_nodes | grep 'Management_Worker') ]]; then rebuild_workers=true; fi
                    if [[ -n $(echo $limit_management_nodes | grep 'Management_Master') ]]; then rebuild_masters=true; fi

                    prepare_images_ouput=$(echo '{{inputs.parameters.global_params}}' | jq -r '.stage_params["prepare-images"].global["prepare-management-images"]["sat-bootprep-run"].script_stdout')
                    update_cfs_conf_ouput=$(echo '{{inputs.parameters.global_params}}' | jq -r '.stage_params["update-cfs-config"].global["update-management-cfs-config"]["sat-bootprep-run"].script_stdout')

                    # check config
                    configuration=$(echo $update_cfs_conf_ouput | jq '.configurations[].name' | tr -d '"')
                    if [[ -z $configuration ]]; then echo "ERROR  no CFS configuration was recieved from update-cfs-config stage"; exit 1; fi
                    if [[ $(echo $configuration | wc -l) -gt 1 ]]; then 
                      echo "ERROR  more than 1 configruation was recieved. There must be exactly 1 CFS configuration to for a rebuild"
                      echo "ERROR  CFS configurations recieved: $configuration"; exit 1
                    fi
                    cray cfs configurations describe "$configuration" > /dev/null
                    if [[ $? -ne 0 ]]; then
                      exit 1 # could not find the desired cfs configuration
                    else
                      echo "NOTICE found CFS configuration:$configuration in CFS"
                    fi

                    if $rebuild_workers; then
                      # Check image exists
                      image=$(echo $prepare_images_ouput | jq '.images | map(select(.configuration_group_names[] == "Management_Worker")) | .[].final_image_id' | tr -d '"')
                      if [[ -z $image ]]; then echo "ERROR  no image was recieved for 'Management_Worker' from prepare images stage"; exit 1; fi
                      if [[ $(echo $image | wc -l) -gt 1 ]]; then 
                        echo "ERROR  more than 1 image was recieved for Management_Worker nodes. Must be exactly 1 image to rebuild"
                        echo "ERROR  Images recieved: $image"; exit 1
                      fi
                      cray ims images describe "$image" > /dev/null
                      if [[ $? -ne 0 ]]; then
                        exit 1 # could not find the image in IMS
                      else
                        echo "NOTICE found image:$image in IMS for Management_Worker rebuild"
                      fi
                    fi

                    if $rebuild_masters; then
                      # Check image exists
                      image=$(echo $prepare_images_ouput | jq '.images | map(select(.configuration_group_names[] == "Management_Master")) | .[].final_image_id' | tr -d '"')
                      if [[ -z $image ]]; then echo "ERROR  no image was recieved for 'Management_Master' from prepare images stage"; exit 1; fi
                      if [[ $(echo $image | wc -l) -gt 1 ]]; then 
                        echo "ERROR  more than 1 image was recieved for Management_Master nodes. Must be exactly 1 image to rebuild"
                        echo "ERROR  Images recieved: $image"; exit 1
                      fi
                      cray ims images describe "$image" > /dev/null
                      if [[ $? -ne 0 ]]; then
                        exit 1 # could not find the image in IMS
                      else
                        echo "NOTICE found image:$image in IMS for Management_Master rebuild"
                      fi
                    fi
          - name: get-worker-rebuild-sets
            dependencies:
              - verify-images-and-configuration
            templateRef:
              name: ssh-template
              template: shell-script
            arguments:
              parameters:
                - name: dryRun
                  value: "{{$.DryRun}}"
                - name: scriptContent
                  value: |
                    limit_management_nodes=$(echo '{{inputs.parameters.global_params}}' | jq -r '.input_params.limit_management_nodes[]')
                    if [[ -n $(echo $limit_management_nodes | grep 'Management_Worker') ]]; then
                      worker_nodes=$(kubectl get node --selector='!node-role.kubernetes.io/master' --no-headers=true | awk '{print $1}' | tr "\n", " ")
                      labeled_workers=$(kubectl get nodes --selector='iuf-prevent-rollout=true' -o jsonpath='{range .items[*]}{@.metadata.name}{" "}')
                      for labeled_worker in $labeled_workers; do
                        worker_nodes=$(echo $worker_nodes | sed s/"$labeled_worker"//)
                      done

                      # split nodes into sets to rebuild
                      percent_rollout=$(echo '{{inputs.parameters.global_params}}' | jq -r '.input_params.concurrent_management_rollout_percentage')
                      number_of_sets=$((100 / $percent_rollout))
                      if [[ $percent_rollout -lt 100 ]] && [[ $number_of_sets -lt 2 ]]; then
                        number_of_sets=2   # if 100% is not specified, we do not want only 1 set
                      fi
                      array_nodes_to_rebuild=($worker_nodes)
                      num_nodes_to_rebuild=${#array_nodes_to_rebuild[@]}
                      rebuild_set_size=$(( $num_nodes_to_rebuild / $number_of_sets ))
                      if [[ $rebuild_set_size -eq 0 ]]; then rebuild_set_size=1; fi
                      index=0
                      set=""
                      output=""
                      for node in $worker_nodes; do
                        index=$(( $index + 1 ))
                        set="${set},""$node"
                        if [[ $index -eq $rebuild_set_size ]]; then
                          output="${output},"$(printf '{"set":"%s"}' "${set#?}")
                          index=0
                          set=""
                        fi
                      done
                      if [[ -n $set ]]; then
                        output="${output},""$(printf {"set":"%s"} "${set#?}")"
                      fi
                      echo "[""${output#?}""]"
                    else
                      echo '[{"INFO":  "Not rebuilding worker nodes because Management_Worker was not in --limit-management-rollout"}]'
                    fi
          - name: rebuild-worker-nodes
            dependencies:
              - get-worker-rebuild-sets
            template: rebuild-set-of-workers
            arguments:
              parameters:
                - name: nodes
                  value: "{{item}}"
            withParam: "{{tasks.get-worker-rebuild-sets.outputs.result}}"
          - name: rebuild-m002
            dependencies:
              - rebuild-worker-nodes
            templateRef:
              name: iuf-base-template
              template: shell-script
            arguments:
              parameters:
                - name: dryRun
                  value: "{{$.DryRun}}"
                - name: scriptContent
                  value: |
                    limit_management_nodes=$(echo '{{inputs.parameters.global_params}}' | jq -r '.input_params.limit_management_nodes[]')
                    if [[ -z $(echo $limit_management_nodes | grep 'Management_Master') ]]; then 
                      echo "NOTICE  Not rebuilding ncn-m002 nodes because 'Management_Master' was not in --limit-management-rollout"
                      exit 0
                    fi
                    labeled_nodes=$(kubectl get nodes --selector='iuf-prevent-rollout=true' -o jsonpath='{range .items[*]}{@.metadata.name}{" "}')
                    if [[ -n $(echo $labeled_nodes | grep ncn-m002) ]]; then
                      echo "NOTICE  ncn-m002 is labeled with 'iuf-prevent-rollout=true' which means it will not be rebuilt"
                      exit 0
                    fi
                    master_nodes=$(kubectl get node --selector='node-role.kubernetes.io/master' --no-headers=true | awk '{print $1}' | tr "\n", " ")
                    if [[ -z $(echo $master_nodes | grep ncn-m002) ]]; then 
                      echo "ERROR  ncn-m002 was not found in kubernetes master nodes. The search was via kubectl get node --selector='node-role.kubernetes.io/master'"
                      exit 1
                    fi
                    
                    echo "NOTICE  updating CFS config on ncn-m002"
                    TARGET_NCN=ncn-m002
                    TARGET_XNAME=$(curl -s -k -H "Authorization: Bearer ${TOKEN}" "https://api-gw-service-nmn.local/apis/sls/v1/search/hardware?extra_properties.Role=Management" | \
                      jq -r ".[] | select(.ExtraProperties.Aliases[] | contains(\"$TARGET_NCN\")) | .Xname")
                    update_cfs_conf_ouput=$(echo '{{inputs.parameters.global_params}}' | jq -r '.stage_params["update-cfs-config"].global["update-management-cfs-config"]["sat-bootprep-run"].script_stdout')
                    configuration=$(echo $update_cfs_conf_ouput | jq '.configurations[].name' | tr -d '"')
                    cray cfs components update ${TARGET_XNAME} --enabled false --desired-config "${configuration}"

                    echo "NOTICE  updating boot-image in BSS on ncn-m002"
                    prepare_images_ouput=$(echo '{{inputs.parameters.global_params}}' | jq -r '.stage_params["prepare-images"].global["prepare-management-images"]["sat-bootprep-run"].script_stdout')
                    IMAGE_ID=$(echo $prepare_images_ouput | jq '.images | map(select(.configuration_group_names[] == "Management_Master")) | .[].final_image_id' | tr -d '"')
                    image_manifest_str=$(cray ims images describe $IMAGE_ID --format json | jq '.link.path')
                    image_manifest_str=${image_manifest_str#*s3://}
                    bucket="$( cut -d '/' -f 1 <<< "$image_manifest_str" )"
                    bucket_rm="${bucket}/"
                    path=${image_manifest_str#*${bucket_rm}}
                    path=${path%?}
                    temp_file="/tmp/$(echo $RANDOM | md5sum | head -c 21; echo).json"
                    cray artifacts get $bucket $path $temp_file
                    metal_image=$(jq '.artifacts | map({"path": .link.path, "type": .type}) | .[] | select( .type == "application/vnd.cray.image.rootfs.squashfs") | .path ' < $temp_file)
                    echo "INFO  Setting metal.server image to: $metal_image"
                    kernel_image=$(jq '.artifacts | map({"path": .link.path, "type": .type}) | .[] | select( .type == "application/vnd.cray.image.kernel") | .path ' < $temp_file)
                    kernel_image=$(echo "$kernel_image" | tr -d '"')
                    echo "INFO Setting kernel image to: $kernel_image"
                    initrd_image=$(jq '.artifacts | map({"path": .link.path, "type": .type}) | .[] | select( .type == "application/vnd.cray.image.initrd") | .path ' < $temp_file)
                    initrd_image=$(echo "$initrd_image" | tr -d '"')
                    echo "INFO  Setting initrd image to: $initrd_image"
                    METAL_SERVER=$(cray bss bootparameters list --hosts "${TARGET_XNAME}" --format json | jq '.[] |."params"' \
                    | awk -F 'metal.server=' '{print $2}' \
                    | awk -F ' ' '{print $1}')
                    NEW_METAL_SERVER=$metal_image
                    PARAMS=$(cray bss bootparameters list --hosts "${TARGET_XNAME}" --format json | jq '.[] |."params"' | \
                        sed "/metal.server/ s|${METAL_SERVER}|${NEW_METAL_SERVER}|" | \
                        tr -d \")
                    cray bss bootparameters update --hosts "${TARGET_XNAME}" \
                      --kernel $kernel_image \
                      --initrd $initrd_image \
                      --params "${PARAMS}"

                    export TERM=linux
                    echo "NOTICE  rebuilding ncn-m002"
                    # /usr/share/doc/csm/upgrade/scripts/rebuild/ncn-rebuild-master-nodes.sh ncn-m002
          - name: rebuild-m003
            dependencies:
              - rebuild-m002
            templateRef:
              name: iuf-base-template
              template: shell-script
            arguments:
              parameters:
                - name: dryRun
                  value: "{{$.DryRun}}"
                - name: scriptContent
                  value: |
                    limit_management_nodes=$(echo '{{inputs.parameters.global_params}}' | jq -r '.input_params.limit_management_nodes[]')
                    if [[ -z $(echo $limit_management_nodes | grep 'Management_Master') ]]; then 
                      echo "NOTICE  Not rebuilding ncn-m003 nodes because 'Management_Master' was not in --limit-management-rollout"
                      exit 0
                    fi
                    labeled_nodes=$(kubectl get nodes --selector='iuf-prevent-rollout=true' -o jsonpath='{range .items[*]}{@.metadata.name}{" "}')
                    if [[ -n $(echo $labeled_nodes | grep ncn-m003) ]]; then
                      echo "NOTICE  ncn-m003 is labeled with 'iuf-prevent-rollout=true' which means it will not be rebuilt"
                      exit 0
                    fi
                    master_nodes=$(kubectl get node --selector='node-role.kubernetes.io/master' --no-headers=true | awk '{print $1}' | tr "\n", " ")
                    if [[ -z $(echo $master_nodes | grep ncn-m003) ]]; then 
                      echo "ERROR  ncn-m003 was not found in kubernetes master nodes. The search was via kubectl get node --selector='node-role.kubernetes.io/master'"
                      exit 1
                    fi
                    
                    echo "NOTICE  updating CFS config on ncn-m003"
                    TARGET_NCN=ncn-m003
                    TARGET_XNAME=$(curl -s -k -H "Authorization: Bearer ${TOKEN}" "https://api-gw-service-nmn.local/apis/sls/v1/search/hardware?extra_properties.Role=Management" | \
                      jq -r ".[] | select(.ExtraProperties.Aliases[] | contains(\"$TARGET_NCN\")) | .Xname")
                    update_cfs_conf_ouput=$(echo '{{inputs.parameters.global_params}}' | jq -r '.stage_params["update-cfs-config"].global["update-management-cfs-config"]["sat-bootprep-run"].script_stdout')
                    configuration=$(echo $update_cfs_conf_ouput | jq '.configurations[].name' | tr -d '"')
                    cray cfs components update ${TARGET_XNAME} --enabled false --desired-config "${configuration}"

                    echo "NOTICE  updating boot-image in BSS on ncn-m003"
                    prepare_images_ouput=$(echo '{{inputs.parameters.global_params}}' | jq -r '.stage_params["prepare-images"].global["prepare-management-images"]["sat-bootprep-run"].script_stdout')
                    IMAGE_ID=$(echo $prepare_images_ouput | jq '.images | map(select(.configuration_group_names[] == "Management_Master")) | .[].final_image_id' | tr -d '"')
                    image_manifest_str=$(cray ims images describe $IMAGE_ID --format json | jq '.link.path')
                    image_manifest_str=${image_manifest_str#*s3://}
                    bucket="$( cut -d '/' -f 1 <<< "$image_manifest_str" )"
                    bucket_rm="${bucket}/"
                    path=${image_manifest_str#*${bucket_rm}}
                    path=${path%?}
                    temp_file="/tmp/$(echo $RANDOM | md5sum | head -c 21; echo).json"
                    cray artifacts get $bucket $path $temp_file
                    metal_image=$(jq '.artifacts | map({"path": .link.path, "type": .type}) | .[] | select( .type == "application/vnd.cray.image.rootfs.squashfs") | .path ' < $temp_file)
                    echo "INFO  Setting metal.server image to: $metal_image"
                    kernel_image=$(jq '.artifacts | map({"path": .link.path, "type": .type}) | .[] | select( .type == "application/vnd.cray.image.kernel") | .path ' < $temp_file)
                    kernel_image=$(echo "$kernel_image" | tr -d '"')
                    echo "INFO Setting kernel image to: $kernel_image"
                    initrd_image=$(jq '.artifacts | map({"path": .link.path, "type": .type}) | .[] | select( .type == "application/vnd.cray.image.initrd") | .path ' < $temp_file)
                    initrd_image=$(echo "$initrd_image" | tr -d '"')
                    echo "INFO  Setting initrd image to: $initrd_image"
                    METAL_SERVER=$(cray bss bootparameters list --hosts "${TARGET_XNAME}" --format json | jq '.[] |."params"' \
                    | awk -F 'metal.server=' '{print $2}' \
                    | awk -F ' ' '{print $1}')
                    NEW_METAL_SERVER=$metal_image
                    PARAMS=$(cray bss bootparameters list --hosts "${TARGET_XNAME}" --format json | jq '.[] |."params"' | \
                        sed "/metal.server/ s|${METAL_SERVER}|${NEW_METAL_SERVER}|" | \
                        tr -d \")
                    cray bss bootparameters update --hosts "${TARGET_XNAME}" \
                      --kernel $kernel_image \
                      --initrd $initrd_image \
                      --params "${PARAMS}"

                    export TERM=linux
                    echo "NOTICE  rebuilding ncn-m003"
                    # /usr/share/doc/csm/upgrade/scripts/rebuild/ncn-rebuild-master-nodes.sh ncn-m003
          - name: end-operation
            dependencies:
              - rebuild-m003
            templateRef:
              name: workflow-template-record-time-template
              template: record-time-template
          - name: prom-metrics
            dependencies:
              - start-operation
              - end-operation
            template: prom-metrics
            arguments:
              parameters:
              - name: opstart
                value: "{{tasks.start-operation.outputs.result}}"
              - name: opend
                value: "{{tasks.end-operation.outputs.result}}"
    - name: rebuild-set-of-workers
      inputs:
        parameters:
          - name: nodes
      dag:
        tasks:
          - name: rebuild-set
            templateRef:
              name: ssh-template
              template: shell-script
            arguments:
              parameters:
              - name: dryRun
                value: "{{$.DryRun}}"
              - name: scriptContent
                value: |
                  limit_management_nodes=$(echo '{{inputs.parameters.global_params}}' | jq -r '.input_params.limit_management_nodes[]')
                  if [[ -z $(echo $limit_management_nodes | grep 'Management_Worker') ]]; then
                    echo "NOTICE  Not rebuilding worker nodes because 'Management_Worker' was not in --limit-management-rollout"
                    exit 0
                  fi
                  echo "NOTICE  rebuild: {{inputs.parameters.nodes}}"
                  rebuild_set="{{inputs.parameters.nodes}}"
                  rebuild_set=${rebuild_set#"{set:"}
                  rebuild_set=${rebuild_set%"}"}
                  if [[ -z $rebuild_set ]]; then
                    echo "NOTICE  this step recieved no nodes to rebuild. Continuing without rebuilding any worker nodes"
                    exit 0
                  fi
                  prepare_images_ouput=$(echo '{{inputs.parameters.global_params}}' | jq -r '.stage_params["prepare-images"].global["prepare-management-images"]["sat-bootprep-run"].script_stdout')
                  image=$(echo $prepare_images_ouput | jq '.images | map(select(.configuration_group_names[] == "Management_Worker")) | .[].final_image_id' | tr -d '"')
                  update_cfs_conf_ouput=$(echo '{{inputs.parameters.global_params}}' | jq -r '.stage_params["update-cfs-config"].global["update-management-cfs-config"]["sat-bootprep-run"].script_stdout')
                  configuration=$(echo $update_cfs_conf_ouput | jq '.configurations[].name' | tr -d '"')

                  export TERM=linux
                  echo "NOTICE  starting rebuild of $rebuild_set"
                  echo "INFO  using image: $image"
                  echo "INFO  using cfs-configuration: $configuration"
                  /usr/share/doc/csm/upgrade/scripts/upgrade/ncn-upgrade-worker-storage-nodes.sh $rebuild_set --dry-run --image-id $image --desired-cfs-conf $configuration
    - name: prom-metrics
      inputs:
        parameters:
        - name: opstart
        - name: opend
      metrics:
        prometheus:
          - name: operation_time
            help: "Duration gauge by operation name in seconds"
            labels:
              - key: "opname"
                value: "management-nodes-rollout"
              - key: stage
                value: "management-nodes-rollout"
              - key: type
                value: "global"
              - key: pdname
                value: "global"
              - key: pdversion
                value: "global"
              - key: "opstart"
                value: "{{inputs.parameters.opstart}}"
              - key: "opend"
                value: "{{inputs.parameters.opend}}"
            gauge:
              value: "{{outputs.parameters.diff-time-value}}"
      outputs:
        parameters:
          - name: diff-time-value
            globalName: diff-time-value
            valueFrom:
              path: /tmp/diff_time.txt
      container:
        image: artifactory.algol60.net/csm-docker/stable/docker.io/alpine/git:2.32.0
        command: [sh, -c]
        args: ["DIFF_TIME=$(expr {{inputs.parameters.opend}} - {{inputs.parameters.opstart}}); echo $DIFF_TIME; echo $DIFF_TIME > /tmp/diff_time.txt"]
